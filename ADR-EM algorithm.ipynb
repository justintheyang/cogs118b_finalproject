{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Adaptive Dimension Reduction Expectation Maximization (ADR-EM) algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ding C, Xiaofeng He, Hongyuan Zha, Simon HD (2002). “Adaptive Dimension Reduction for\n",
    "Clustering High Dimensional Data.” In *Proceedings 2002 IEEE International Conference on Data\n",
    "Mining*, 147–154."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.cluster import fowlkes_mallows_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Scale and visualize the embedding vectors\n",
    "def plot_embedding(X, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_npca = np.load('data/sketches_raw_nopca.npy')\n",
    "fc6_npca = np.load('data/sketches_fc6_nopca.npy')\n",
    "raw_pca  = np.load('data/sketches_raw_pca.npy')\n",
    "fc6_pca  = np.load('data/sketches_fc6_pca.npy')\n",
    "metadata = pd.read_csv('data/sketches_metadata.csv')\n",
    "metadata['category_factored'] = LabelEncoder().fit_transform(metadata.category)\n",
    "\n",
    "feature_set = [raw_npca, fc6_npca, raw_pca, fc6_pca]\n",
    "labels_set  = [metadata.sort_values(col).category_factored.values \n",
    "               for col in metadata.drop(columns=['category', 'category_factored']).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 32 # we want 32 clusters\n",
    "r = K - 1 # reduced-dimension subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_set[-1]\n",
    "features = feature_set[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to mean 0 variance 1 per dimension\n",
    "features = features - features.mean(axis=0) + (np.random.rand() / 1000000)\n",
    "features /= features.std(axis=0)\n",
    "features = PCA(n_components=r).fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 0 | score: 0.03436982437844208\n",
      "On iteration 1 | score: 0.034309462657735185\n",
      "On iteration 2 | score: 0.03344988328969336\n",
      "On iteration 3 | score: 0.03358678062246045\n",
      "On iteration 4 | score: 0.033463462134777536\n",
      "On iteration 5 | score: 0.03390613475726522\n",
      "On iteration 6 | score: 0.03317221294299476\n",
      "On iteration 7 | score: 0.033369081873519016\n",
      "On iteration 8 | score: 0.03401252153887691\n",
      "On iteration 9 | score: 0.03317245066302933\n",
      "On iteration 10 | score: 0.03443579427974891\n",
      "On iteration 11 | score: 0.0344635299357771\n",
      "On iteration 12 | score: 0.03471251726948786\n",
      "On iteration 13 | score: 0.03346215719753251\n",
      "On iteration 14 | score: 0.03370646932954293\n",
      "On iteration 15 | score: 0.0329305227724656\n",
      "On iteration 16 | score: 0.033829239338318544\n",
      "On iteration 17 | score: 0.03349232133322897\n",
      "On iteration 18 | score: 0.03340476068905491\n",
      "On iteration 19 | score: 0.03373636762994072\n",
      "On iteration 20 | score: 0.0329854410485013\n",
      "On iteration 21 | score: 0.03409499754332015\n",
      "On iteration 22 | score: 0.0329507830066314\n",
      "On iteration 23 | score: 0.032908997964100926\n",
      "On iteration 24 | score: 0.03329334501855781\n",
      "On iteration 25 | score: 0.033234762320454\n",
      "On iteration 26 | score: 0.033968225629623136\n",
      "On iteration 27 | score: 0.03405385168048952\n",
      "On iteration 28 | score: 0.03383747322012092\n",
      "On iteration 29 | score: 0.03333242457562888\n",
      "On iteration 30 | score: 0.034000789501394874\n",
      "On iteration 31 | score: 0.03368279308398403\n",
      "On iteration 32 | score: 0.034190082811041474\n",
      "On iteration 33 | score: 0.03315792334070126\n",
      "On iteration 34 | score: 0.033800696882148484\n",
      "On iteration 35 | score: 0.03299819959993208\n",
      "On iteration 36 | score: 0.033048895525018746\n",
      "On iteration 37 | score: 0.03361480686043569\n",
      "On iteration 38 | score: 0.03317127484143542\n",
      "On iteration 39 | score: 0.03385702759927436\n",
      "On iteration 40 | score: 0.03426911941543648\n",
      "On iteration 41 | score: 0.03466563820615981\n",
      "On iteration 42 | score: 0.034596994534578776\n",
      "On iteration 43 | score: 0.033175545513066854\n",
      "On iteration 44 | score: 0.032709031276428324\n",
      "On iteration 45 | score: 0.03277219895208384\n",
      "On iteration 46 | score: 0.03357906774520235\n",
      "On iteration 47 | score: 0.034031199554334396\n",
      "On iteration 48 | score: 0.03421159351369959\n",
      "On iteration 49 | score: 0.03339130454974935\n",
      "On iteration 50 | score: 0.03393967951640826\n",
      "On iteration 51 | score: 0.03426184697675882\n",
      "On iteration 52 | score: 0.03307707491574318\n",
      "On iteration 53 | score: 0.033235107035304655\n",
      "On iteration 54 | score: 0.03343930857703765\n",
      "On iteration 55 | score: 0.03332253642803682\n",
      "On iteration 56 | score: 0.032984504790372356\n",
      "On iteration 57 | score: 0.03318805441147096\n",
      "On iteration 58 | score: 0.033132613636394574\n",
      "On iteration 59 | score: 0.03368970828636857\n",
      "On iteration 60 | score: 0.03356743797882357\n",
      "On iteration 61 | score: 0.033743961153402335\n",
      "On iteration 62 | score: 0.03304867190053188\n",
      "On iteration 63 | score: 0.03327940217185694\n",
      "On iteration 64 | score: 0.03288731379576631\n",
      "On iteration 65 | score: 0.03351892402479825\n",
      "On iteration 66 | score: 0.033647364732727975\n",
      "On iteration 67 | score: 0.034021345459976364\n",
      "On iteration 68 | score: 0.03300724724755837\n",
      "On iteration 69 | score: 0.03376060580300293\n",
      "On iteration 70 | score: 0.03373811382047213\n",
      "On iteration 71 | score: 0.03311265061219013\n",
      "On iteration 72 | score: 0.03280113044906682\n",
      "On iteration 73 | score: 0.033410789358206745\n",
      "On iteration 74 | score: 0.03347989988758592\n",
      "On iteration 75 | score: 0.033319245442032464\n",
      "On iteration 76 | score: 0.03368131138956471\n",
      "On iteration 77 | score: 0.034199730751762664\n",
      "On iteration 78 | score: 0.033754996978752005\n",
      "On iteration 79 | score: 0.03280218173487508\n",
      "On iteration 80 | score: 0.03320254744479392\n",
      "On iteration 81 | score: 0.03281356718229211\n",
      "On iteration 82 | score: 0.033768402042912087\n",
      "On iteration 83 | score: 0.03262635582849792\n",
      "On iteration 84 | score: 0.034636317282701556\n",
      "On iteration 85 | score: 0.034255835712409005\n",
      "On iteration 86 | score: 0.03324045943533119\n",
      "On iteration 87 | score: 0.0329774616363295\n",
      "On iteration 88 | score: 0.032143573332192456\n",
      "On iteration 89 | score: 0.033049602991860993\n",
      "On iteration 90 | score: 0.0335117474189951\n",
      "On iteration 91 | score: 0.03393731006331783\n",
      "On iteration 92 | score: 0.03392785073804927\n",
      "On iteration 93 | score: 0.03353540029649905\n",
      "On iteration 94 | score: 0.0325858876606154\n",
      "On iteration 95 | score: 0.034014974553773294\n",
      "On iteration 96 | score: 0.03378615888257848\n",
      "On iteration 97 | score: 0.033427666555533565\n",
      "On iteration 98 | score: 0.034394762703030775\n",
      "On iteration 99 | score: 0.03387211750159369\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    pred_labels = GaussianMixture(n_components=K, random_state=0).fit_predict(features)\n",
    "    features = LinearDiscriminantAnalysis().fit_transform(features, pred_labels)\n",
    "    print(f'On iteration {i} | score: {fowlkes_mallows_score(labels, pred_labels)}')\n",
    "#     features_TSNE = TSNE(n_components=2,random_state=0).fit_transform(features)\n",
    "#     y=pred_labels\n",
    "#     plot_embedding(features_TSNE, f\"t-SNE embedding on iteration {i+1}\")\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
